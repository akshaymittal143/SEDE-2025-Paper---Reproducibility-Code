# RAG-Based Vulnerability Detection: Reproducibility Artifacts

[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Conference](https://img.shields.io/badge/Conference-SEDE%202025-green)](https://sede-conference.org/)
[![Paper](https://img.shields.io/badge/Paper-Submitted-green)](https://sede-conference.org/)
[![Status](https://img.shields.io/badge/Status-Final%20Version-brightgreen)](https://github.com/akshaymittal143/SEDE-2025-Paper---Reproducibility-Code)

> ðŸ“– **Paper**: "GenSecAI-Ops: Integrating Generative AI and RAG for Proactive DevSecOps Security"
> 
> ðŸ›ï¸ **Venue**: 34th International Conference on Software Engineering and Data Engineering (SEDE 2025)
> 
> ðŸ‘¥ **Authors**: Akshay Mittal et al.
> 
> âœ… **Status**: **Final submission completed** - All reproducibility artifacts ready

---

## ðŸŽ¯ Abstract

This repository contains the **final** experimental code, data, and reproducibility artifacts for our SEDE 2025 paper on the GenSecAI-Ops framework. Our work presents a comprehensive solution for integrating Generative AI and RAG into DevSecOps workflows, achieving **82% F1-score** for vulnerability detection with **<5% hallucination rate** and **91% remediation correctness**.

ðŸŽ‰ **Paper Status**: Final version submitted to SEDE 2025 with all formatting requirements met.

## ðŸ“ Repository Structure

```
reproducibility/
â”œâ”€â”€ ðŸ“‹ README.md                 # This file
â”œâ”€â”€ ðŸ“¦ requirements.txt          # Python dependencies
â”œâ”€â”€ ðŸ“‚ scripts/                  # Experimental scripts
â”‚   â”œâ”€â”€ ðŸ“„ README.md            # Detailed execution guide
â”‚   â”œâ”€â”€ ðŸŽ¯ confusion_matrix.py  # Performance visualization
â”‚   â”œâ”€â”€ ðŸ”¬ ablation_rag_alpha.py # Parameter sensitivity study
â”‚   â”œâ”€â”€ ðŸ§  hallucination_eval.py # RAG hallucination analysis
â”‚   â”œâ”€â”€ â±ï¸  simulate_latency.py   # Performance benchmarking
â”‚   â””â”€â”€ ðŸš€ run_all.sh           # Complete reproduction script
â”œâ”€â”€ ðŸ’¾ data/                     # Experimental results
â”‚   â”œâ”€â”€ alpha_ablation.csv       # Ablation study results
â”‚   â”œâ”€â”€ latency_summary.csv      # Performance benchmarks
â”‚   â””â”€â”€ hallucination_summary.*  # Hallucination metrics
â””â”€â”€ ðŸ“Š figures/                  # Publication-ready visualizations
    â”œâ”€â”€ confusion_matrix.*       # Classification performance
    â”œâ”€â”€ alpha_ablation.*         # Parameter sensitivity plots
    â””â”€â”€ latency.*               # Performance analysis
```

## ðŸš€ Quick Start

### Prerequisites

- **Python 3.7+**
- **Git** (for cloning)
- **Virtual environment support** (recommended)

### Installation & Execution

```bash
# 1. Clone the repository
git clone https://github.com/akshaymittal143/SEDE-2025-Paper---Reproducibility-Code.git
cd SEDE-2025-Paper---Reproducibility-Code

# 2. Create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run complete reproduction
cd scripts
bash run_all.sh

# 5. Check generated outputs
ls -la ../figures/  # Visualizations
ls -la ../data/     # Raw results
```

### Individual Experiments

```bash
# Core performance evaluation
python scripts/confusion_matrix.py

# Parameter sensitivity analysis
python scripts/ablation_rag_alpha.py

# System performance benchmarking
python scripts/simulate_latency.py

# Hallucination detection evaluation
python scripts/hallucination_eval.py
```

## ðŸ”¬ Experimental Design

### Research Questions

1. **RQ1**: How can GenSecAI-Ops integrate generative AI across CI/CD pipeline stages for proactive security?
2. **RQ2**: What is the effectiveness of RAG-grounded agents for vulnerability detection and remediation?
3. **RQ3**: How does the framework perform in terms of detection accuracy, latency, and developer trust?
4. **RQ4**: What is the extent of hallucination mitigation through knowledge grounding?

### Methodology

- **Framework**: GenSecAI-Ops multi-agent architecture with RAG grounding
- **Pipeline Integration**: GitHub Actions and Jenkins CI/CD implementations  
- **Knowledge Base**: Cybersecurity Knowledge Graph (CSKG) with NVD, OWASP, MITRE ATT&CK
- **Evaluation Metrics**: F1-Score, Remediation Correctness, Hallucination Rate, Developer Trust
- **Statistical Analysis**: Paired t-tests with Holm-Å Ã­dÃ¡k correction (p < 0.01)

### Key Results

| Metric | Performance |
|--------|------------|
| **Accuracy** | 85.0% |
| **Precision** | 83.7% |
| **Recall** | 80.4% |
| **F1-Score** | 82.0% |
| **Latency** | <100ms |

## ðŸ“Š Generated Artifacts

### Figures
- **`confusion_matrix.{pdf,png}`**: Classification performance heatmap
- **`alpha_ablation.{pdf,png}`**: Parameter sensitivity analysis
- **`latency.{pdf,png}`**: Performance benchmarking results

### Data Files
- **`alpha_ablation.csv`**: Raw ablation study metrics
- **`latency_summary.csv`**: Performance timing data
- **`hallucination_summary.{json,csv}`**: RAG hallucination analysis

## ðŸ› ï¸ Technical Details

### Dependencies

| Package | Version | Purpose |
|---------|---------|----------|
| `numpy` | Latest | Numerical computations |
| `matplotlib` | Latest | Visualization framework |
| `seaborn` | Latest | Statistical plotting |
| `scikit-learn` | Latest | ML metrics and utilities |

### System Requirements

- **RAM**: Minimum 4GB, Recommended 8GB+
- **Storage**: ~50MB for generated artifacts
- **Runtime**: ~5-10 minutes for complete reproduction

### Output Formats

- **Vector Graphics**: PDF format for publication
- **Raster Graphics**: High-DPI PNG (600 DPI) for presentations
- **Data**: CSV/JSON formats for further analysis

## ðŸ”„ Reproducibility

### Deterministic Results

All experiments use **fixed random seeds** (`np.random.seed(42)`) to ensure reproducible results across different environments.

### Environment Consistency

```bash
# Check Python version compatibility
python --version  # Should be 3.7+

# Verify package versions
pip list

# Compare generated checksums (optional)
find figures/ -name "*.pdf" -exec shasum {} \;
```

### Expected Runtime

| Script | Estimated Time | Output Files |
|--------|----------------|-------------|
| `confusion_matrix.py` | ~30s | 2 files |
| `ablation_rag_alpha.py` | ~2min | 3 files |
| `simulate_latency.py` | ~1min | 3 files |
| `hallucination_eval.py` | ~1min | 2 files |
| **Total** | **~5min** | **10 files** |

## ðŸ“ Citation

If you use this code or data in your research, please cite our paper:

```bibtex
@inproceedings{mittal2025gensecai,
  title={GenSecAI-Ops: Integrating Generative AI and RAG for Proactive DevSecOps Security},
  author={Akshay Mittal and [Co-authors]},
  booktitle={Proceedings of the 34th International Conference on Software Engineering and Data Engineering},
  series={SEDE '25},
  year={2025},
  publisher={ACM},
  note={Final submission - under review},
  url={https://github.com/akshaymittal143/SEDE-2025-Paper---Reproducibility-Code}
}
```

## ðŸ¤ Contributing

We welcome contributions to improve reproducibility:

- **Issues**: Report bugs or inconsistencies
- **Pull Requests**: Enhance documentation or fix issues
- **Extensions**: Adapt experiments for new datasets

## ðŸ“§ Contact

- **Primary Author**: akshay.mittal@ieee.org
- **Repository**: https://github.com/akshaymittal143/SEDE-2025-Paper---Reproducibility-Code
- **Issues**: Use GitHub Issues for technical problems
- **Paper Questions**: Contact authors via institutional email

## ðŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- SEDE 2025 Conference organizers
- Anonymous reviewers for valuable feedback
- Open-source community for tools and libraries

---

> ðŸ’¡ **Tip**: For the best reproduction experience, use a fresh Python virtual environment and follow the exact steps in the Quick Start guide.
